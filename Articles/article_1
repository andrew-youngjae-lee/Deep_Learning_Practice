    시츄 이미지에 Overfitting된 모델은 수많은 강아지 사진 중에서 시츄를 정확히 찾아내지만 개/고양이 Classification 문제에서 치와와나 스피치를 고양이로 분류하는 치명적인 실수를 저지른다. 
당신의 사고 모델은 어떤가? 어떤 신념체계에 과하게 Overfitting 되어있지는 않은가? 그래서 옳고/그름의 Classification 문제에서 치명적인 실수를 저지르지는 않는가? 

사회적으로 정립된, 그리고 우리가 궁극적으로 추구하는 올바른 신념체계 = Ground-Truth
너, 나, 우리가 각각 지닌 각자의 신념체계 = 예측 모델(=사유 모델)
우리가 속한 사회에서 발생하는 사건이나 현상 = Data, Dataset
'올바름'과 '현실(현실에서 발생하는 사건이나 현상 Data)' 간의 차이 = Loss

"우리는 어떤 사회에서 살아가며 내부에서 수집되는 Data를 바탕으로 Loss를 끊임없이 줄여가며 우리의 사유모델을 올바른 신념체계에 일치시키는 방향을 추구한다."


사람이 자신의 신념체계에 대한 과신으로 어떤 편견에 빠지고, 편향적인 사고를 하게 되는것은 기계학습이나 
신경망 학습의 과적합(Overfitting) 문제와 유사하다. '사회적으로 정립된 올바른 신념체계'가 장려하고 지향하는 
현상들이 어떤 Ground-Truth Pattern을 가진다고 할 때, 우리 각각의 신념체계는 우리가 속한 사회에서 수집할 수 있는
현상에 대한 Data을 바탕으로 올바른 신념체계를 학습하는 '예측모델'로 이야기할 수 있다. 우리 사회의 '올바른 신념체계'를 
바탕으로 실제로 일어나는 현상이나 사건에는 그런 신념체계에 꼭 부합하는 올바른 현상이 대다수이지만, 당연히 일정량의 noise도 섞여있다. 
청렴정치를 내세우지만 뒤에서는 뇌물을 챙기는 정치인, 평등주의를 외치지만 평등이 자신의 자리나 권위를 위협할때는 
다시 그 평등에 악의적으로 맞서는 사람들이 noise에 속한다. 
noise는 그것이 Ground-Truth에서 벗어나있는것 자체로 유용한데, 예측모델(여기서는 우리의 사유 모델이다)이 자칫 
과적합(Overfitting)에 빠지려할때 noise가 우리의 모델을 다시 '진리'로 끌어당겨준다. 

포퓰리스트 정치인들이 청렴과 평등을 내세우며 균형에서 한참 벗어난 정책을 추구하여 그러한 정책의 실패가 가져온 참담한 결과가 나타날 때, 
혹은 그들이 청렴이나 평등과 거리가 먼 사람들이라는 진실이 드러났을 때 우리는 그들과 거리를 둠으로써 (포퓰리즘과 올바른 신념체계(Ground-Truth)의 
차이가 내놓은 Loss(여기서는 실망감, 배신감으로 설명할 수 있겠다)를 이용하여) 포퓰리즘에 과적합되지 않고 우리의 올바른 신념체계가 
추구했던 균형으로 다시 자리 잡을 수 있다.  

그러나 noise의 국소적 특징(그것이 Ground-Truth에서 벗어나게 만들고 그리하여 그것을 noise로 만든)에 
과하게 부합하는 과적합(Overfitting) 모델은 noise들 각각의 국소적 특징들까지 완벽하게 설명해내지만 
결코 Ground-Truth Pattern을 설명하지는 못한다. (어떤 미신이나 징크스가 과거에 발생한 사건들에 
꼭 맞는 설명을 제공하여 소오름을 유발하지만 절대 미래에 일어날 사건을 예측하지 못하는 이유가 이것이다. 
과거에 이미 주어진 Data에 과적합되어 과거의 데이터에는 꼭 맞아떨어지지만 그것은 사건이나 현상이 가지는 
고유한 Pattern에는 한참 벗어나있기 때문에, 미래에 들어올 Data에 대해서는 올바른 예측을 수행하지 못한다.) 
*YoungJaeLee_Article

평등과 청렴을 외치면서 스스로 그렇지 못한 정치인에게서 멀어지지 못하고 그런 noise에 자신의 사유 모델을 
과적합해버리게 되면, 해당 정치인의 행동에 대해 설명하고 비호하는데는 매우 뛰어난 사람이 될지 모르나 
진정한 정의와 진리에 대한 담론을 내놓지 못하는 사람이 된다.
    
'올바른 신념체계'에 일치하는 훌륭한 '사유 모델'을 가지고자 하는 열망은 누구나 가지고 있지만, 우리는 스스로 고민해보아야 한다. 어떤 noise data에 자신의 사유모델을 과적합시키지는 않는가? 
    
    